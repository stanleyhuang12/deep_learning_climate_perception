from tools_rec import *
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from torch.utils.data import TensorDataset, DataLoader
from sklearn.preprocessing import StandardScaler
from ray import train
from ray import tune
# from ray.train import ScalingConfig
from ray.train.torch import TorchTrainer
from sklearn.model_selection import KFold, train_test_split
from ray import tune
from ray.tune.schedulers import ASHAScheduler # Scheduler 
from torcheval.metrics import R2Score 
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
from plot_graphs import * 
from ray.tune.search import hyperopt #Hyperopt performs tree-structured parzen estimator
from sci_reg import * 

"=====================Bayesian hyperparameter search====================="


data_file_path_geocoded = '/Users/stanleyhuang/Desktop/01 Projects/YAB/cds_climate_change_perception/Climate Change Perceptions/data/CCES2012_CSVFormat_NEW_GEOCODED.csv'
data_file_path_without_county = '/Users/stanleyhuang/Desktop/01 Projects/YAB/cds_climate_change_perception/Climate Change Perceptions/data/CCES2012_CSVFormat_NEW_WC.csv'


search_space_init_configs = {
    'num_layers': tune.randint(1, 8),
    'base_exp': tune.randint(3, 9),
    'lr': tune.loguniform(1e-5, 1e-2),
}

train_configs = {
    'file_path': data_file_path_geocoded,
    'input_dims': 34,
    'output_dims': 1,
    'max_epochs': 100,
    'batch_size': 8192
}

def scale_y(vec): 
    vec -= 3 # CEnter the vector 
    vec *= 0.5 # Scale into smaller values (to avoid values getting close to 1)
    return np.tanh(vec)

def inverse_scale_y(vec): 
    vec = np.arctanh(vec)
    return (vec * 2) + 3 

    
train_configs_without_geocodes = {
    'wo_county': 1, 
    'file_path': data_file_path_without_county,
    'input_dims': 32,
    'output_dims': 1, 
    'max_epochs': 100,
    'batch_size': 16384, 
    'activation_fn': 1, # Overwrite and force the model to perform tanh using a symmetric and scaled value 
}
torch.manual_seed(123)
# os.environ["TUNE_DISABLE_STRICT_METRIC_CHECKING"] = "1"

def new_train_wo_geocodes(config): 
    
    # Train configs is a dictionary of items that does not vary 
    merged_configs = {**train_configs_without_geocodes, **config}
    dataset = load_dataset(merged_configs['file_path'])
    
    X = dataset.drop(['CC12'], axis=1).values.astype(np.float32)
    y = dataset['CC12'].values.reshape(-1, 1).astype(np.float32) - 1 ## Adjusted y axis 
    
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    
    train_idx, valid_idx = next(iter(kf.split(X)))
    X_train, y_train = X[train_idx], y[train_idx]
    X_test, y_test = X[valid_idx], y[valid_idx]
    
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)
        
    # Convert to tensors 
    X_train, y_train = torch.from_numpy(X_train), torch.from_numpy(y_train)
    X_test, y_test = torch.from_numpy(X_test), torch.from_numpy(y_test)
    
    model = initialize_model(merged_configs)
    
    # model = train.torch.prepare_model(model)
    
    criterion = nn.MSELoss()
    metric = R2Score()
    optimizer = optim.Adam(model.parameters(), lr=merged_configs['lr'])
    
    tensor_dataset = TensorDataset(X_train, y_train)
    
    dataloader = DataLoader(tensor_dataset, batch_size=merged_configs['batch_size'], num_workers=4, shuffle=True)
    r2_score_tracker = float('-inf')
    for epoch in range(merged_configs['max_epochs']):
        model.train()
        train_loss = 0 
        
        for batch_X, batch_y in dataloader:
            optimizer.zero_grad()
            outputs = model(batch_X)
            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()
        
        # Compute model R2 
        valid_loss = 0
        model.eval()
        with torch.no_grad(): 
            y_pred = model.forward(X_test)
            valid_loss = criterion(y_pred, y_test)
            valid_loss = valid_loss.item()

            
        averaged_train_loss = train_loss / len(dataloader) # Average training loss per epoch 
        metric.reset()
        metric.update(y_pred, y_test)
        model_r2 = metric.compute().item()
        
        print(f"Epoch {epoch}: Current R2 = {model_r2}, Best R2 = {r2_score_tracker}")
        
        if model_r2 > r2_score_tracker: 
            ## Keep track of best model r2 score and save it as a checkpoint to call or continue from 
            r2_score_tracker = model_r2 
            
            metrics = {
            "step": epoch,
            "train_loss": averaged_train_loss,
            "valid_loss": valid_loss,
            "r2_score": model_r2,
            "best_r2_score": r2_score_tracker
            }
            
            with tempfile.TemporaryDirectory() as tmpdir: 
            ### REVISSE FOR PERSISTENT SˇORAGE PERSISTING CHECKPOINTS 
                checkpoint_to_track = None
                torch.save(
                    model.state_dict(),
                    os.path.join(tmpdir, "model.pth")
                )
                checkpoint_to_track = Checkpoint.from_directory(tmpdir)
                
                tune.report(metrics, checkpoint=checkpoint_to_track)
        
        else: 
            metrics = {
            "step": epoch,
            "train_loss": averaged_train_loss,
            "valid_loss": valid_loss,
            "r2_score": model_r2,
            "best_r2_score": r2_score_tracker
            }
            tune.report(metrics)
        
        print(f'Epoch {epoch}: Training loss {averaged_train_loss}, Validation loss {valid_loss}, R2 Score {model_r2}')


def new_train_fn(config): 
    
    # Train configs is a dictionary of items that does not vary 
    merged_configs = {**train_configs, **config}
    dataset = load_dataset(merged_configs['file_path'])
    
    X = dataset.drop(['CC12'], axis=1).values.astype(np.float32)
    y = dataset['CC12'].values.reshape(-1, 1).astype(np.float32) - 1 ## Adjusted y axis 
    
    if merged_configs.get('scale_y', 'False'): 
        y = scale_y(y_train)
    
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    
    train_idx, valid_idx = next(iter(kf.split(X)))
    X_train, y_train = X[train_idx], y[train_idx]
    X_test, y_test = X[valid_idx], y[valid_idx]
    
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)
        
    # Convert to tensors 
    X_train, y_train = torch.from_numpy(X_train), torch.from_numpy(y_train)
    X_test, y_test = torch.from_numpy(X_test), torch.from_numpy(y_test)
    
    model = initialize_model(merged_configs)
    
    # model = train.torch.prepare_model(model)
    
    criterion = nn.MSELoss()
    metric = R2Score()
    optimizer = optim.Adam(model.parameters(), lr=merged_configs['lr'])
    
    tensor_dataset = TensorDataset(X_train, y_train)
    
    dataloader = DataLoader(tensor_dataset, batch_size=merged_configs['batch_size'], num_workers=4, shuffle=True)
    r2_score_tracker = float('-inf')
    for epoch in range(merged_configs['max_epochs']):
        model.train()
        train_loss = 0 
        
        for batch_X, batch_y in dataloader:
            optimizer.zero_grad()
            outputs = model(batch_X)
            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()
        
        # Compute model R2 
        valid_loss = 0
        model.eval()
        with torch.no_grad(): 
            y_pred = model.forward(X_test)
            valid_loss = criterion(y_pred, y_test)
            valid_loss = valid_loss.item()

            
        averaged_train_loss = train_loss / len(dataloader) # Average training loss per epoch 
        metric.reset()
        metric.update(y_pred, y_test)
        model_r2 = metric.compute().item()
        
        print(f"Epoch {epoch}: Current R2 = {model_r2}, Best R2 = {r2_score_tracker}")
        
        if model_r2 > r2_score_tracker: 
            ## Keep track of best model r2 score and save it as a checkpoint to call or continue from 
            r2_score_tracker = model_r2 
            
            metrics = {
            "step": epoch,
            "train_loss": averaged_train_loss,
            "valid_loss": valid_loss,
            "r2_score": model_r2,
            "best_r2_score": r2_score_tracker
            }
            
            with tempfile.TemporaryDirectory() as tmpdir: 
            ### REVISSE FOR PERSISTENT SˇORAGE PERSISTING CHECKPOINTS 
                checkpoint_to_track = None
                torch.save(
                    model.state_dict(),
                    os.path.join(tmpdir, "model.pth")
                )
                checkpoint_to_track = Checkpoint.from_directory(tmpdir)
                
                tune.report(metrics, checkpoint=checkpoint_to_track)
        
        else: 
            metrics = {
            "step": epoch,
            "train_loss": averaged_train_loss,
            "valid_loss": valid_loss,
            "r2_score": model_r2,
            "best_r2_score": r2_score_tracker
            }
            tune.report(metrics)
        
        print(f'Epoch {epoch}: Training loss {averaged_train_loss}, Validation loss {valid_loss}, R2 Score {model_r2}')

## average epoch is miscalculated 
    
# trainer = TorchTrainer(new_train_fn, train_loop_config=param_configs, 
#                        run_config=tune.RunConfig('/Users/stanleyhuang/Desktop/01 Projects/YAB/cds_climate_change_perception/Climate Change Perceptions/checkpoints/train_practice',
#                                             checkpoint_config=tune.CheckpointConfig(num_to_keep=1, 
#                                                                                checkpoint_score_attribute='valid_loss'))
# )
 
# res = trainer.fit()


# if there is a checkpoint configuration, should we use this to do something? 
asha_scheduler = ASHAScheduler(max_t=100,
                               grace_period=8,
                               reduction_factor=2, 
                               metric='valid_loss',
                               mode='min')

tree_parzen_estimator = hyperopt.HyperOptSearch(metric='valid_loss', 
                                                mode='min')
tuner = tune.Tuner(tune.with_resources(new_train_fn, {"cpu": 2}),  
                   param_space=search_space_init_configs, 
                   tune_config=tune.TuneConfig(num_samples=44,
                                          max_concurrent_trials=4, 
                                          scheduler=asha_scheduler, 
                                          search_alg=tree_parzen_estimator),
                   run_config=tune.RunConfig(name='env_pred_tpe_algo_run',
                                        storage_path='/Users/stanleyhuang/Desktop/01 Projects/YAB/cds_climate_change_perception/Climate Change Perceptions/checkpoints',
                                        checkpoint_config=tune.CheckpointConfig(num_to_keep=10,
                                        checkpoint_score_attribute='valid_loss', 
                                        checkpoint_score_order="min"), 
                                        ), 

                   )

results = tuner.fit()

tuner_wo_geocodes = tune.Tuner(tune.with_resources(new_train_wo_geocodes, {"cpu": 2}),  
                   param_space=search_space_init_configs, 
                   tune_config=tune.TuneConfig(num_samples=44,
                                          max_concurrent_trials=4, 
                                          scheduler=asha_scheduler, 
                                          search_alg=tree_parzen_estimator),
                   run_config=tune.RunConfig(name='env_pred_algo_run_without_county',
                                        storage_path='/Users/stanleyhuang/Desktop/01 Projects/YAB/cds_climate_change_perception/Climate Change Perceptions/checkpoints',
                                        checkpoint_config=tune.CheckpointConfig(num_to_keep=10,
                                        checkpoint_score_attribute='valid_loss', 
                                        checkpoint_score_order="min"), 
                                        ), 
                   )

results_wo_county = tuner_wo_geocodes.fit()

## Restore results woithout county data 
exp_path_wo_county = "/Users/stanleyhuang/Desktop/01 Projects/YAB/cds_climate_change_perception/Climate Change Perceptions/checkpoints/env_pred_algo_run_without_county"

## Export experiment results 
results_wo_county = tune.Tuner.restore(exp_path_wo_county, new_train_wo_geocodes).get_results()
experiment_1 = results_wo_county.get_dataframe()
experiment_1.sort_values(by='best_r2_score', ascending=False, inplace=True)
experiment_1.to_csv('res/experiment_1.csv')

# Load best model 
best_results = results_wo_county.get_best_result(metric='best_r2_score', mode='max')
wo_county_path = best_results.checkpoint.path
merged_configs = {**train_configs_without_geocodes, **best_results.config}
model_data= torch.load(os.path.join(wo_county_path, "model.pth"))
model = initialize_model(merged_configs)
model.load_state_dict(model_data)

# Load data 
df_wo_codes = pd.read_csv(train_configs_without_geocodes['file_path'])
X = df_wo_codes.drop(['CC12'], axis=1).values
y = df_wo_codes['CC12'].values - 1

sc = StandardScaler()
X_fit = sc.fit_transform(X)
lr = LinearRegression()

lr.fit(X, y)
y_pred_lr = lr.predict(X)
print('R2 for Linear Model:', lr.score(X, y))

model.eval()
with torch.no_grad(): 
    X_fit_t = torch.from_numpy(X_fit).float()
    y_t = torch.from_numpy(y).reshape(-1, 1).float()
    y_pred_t = model(X_fit_t)
    r2_scorer = R2Score()
    r2_scorer.update(y_pred_t, y_t)
    r2_score = r2_scorer.compute()
    print(f'R2 score: {r2_score}')
    
y = y.reshape(-1, 1)
y_pred_lr = y_pred_lr.reshape(-1, 1)
y_pred_mlp = y_pred_t.cpu().numpy().reshape(-1, 1)
exp_1_resids = pd.DataFrame(np.hstack((y, y_pred_lr, y_pred_mlp)), columns=['y_actual', 'y_pred_lr', 'y_pred_mlp'])




"""Start of SRM algorithm and comparing residuals"""
exp_1_resids['lr_resids'] = compute_true_residuals(exp_1_resids['y_actual'], exp_1_resids['y_pred_lr'])
exp_1_resids['mlp_resids'] = compute_true_residuals(exp_1_resids['y_actual'], exp_1_resids['y_pred_mlp'])

exp_1_resids['smoothed_resids'] = compute_smoothed_residuals(y=exp_1_resids['y_actual'], 
                                                             baseline_y=exp_1_resids['y_pred_lr'],
                                                             alg_y=exp_1_resids['y_pred_mlp'])

df_wo_geocodes = pd.concat([df_wo_codes, exp_1_resids], axis=1)

mlp_linear_diff = df_wo_geocodes['y_pred_mlp'] - df_wo_geocodes['y_pred_lr']
plt.hist(mlp_linear_diff, color='skyblue', edgecolor='black')
plt.axvline(x=0, color='red')
plt.title('Absolute difference between MLP and linear model predictions')
plt.show()

mlp_linear_resids_diff = df_wo_geocodes['lr_resids'] - df_wo_geocodes['mlp_resids']
plt.hist(mlp_linear_resids_diff, bins=10, color='skyblue', edgecolor='black')
plt.axvline(x=0, color='red')
plt.title('Absolute difference of residuals between MLP and linear model predictions')
plt.show()

smoothed_resids_dist = df_wo_geocodes['smoothed_resids']
plt.hist(smoothed_resids_dist, color='cyan', edgecolor='black')
plt.axvline(x=0, color='red')
plt.title('Distribution of smoothed residuals')
plt.show()


### Stats 
df_wo_geocodes_gender = compare_residuals_by_axes(df=df_wo_geocodes, 
                                                  residuals='smoothed_resids',  
                                                  axes='Gender', 
                                                  mapping={0.0:'f', 1.0:'m'})

df_wo_geocodes_political = compare_residuals_by_axes(df=df_wo_geocodes, 
                                                     residuals='smoothed_resids', 
                                                     axes='ideologyd1', 
                                                     )

df_wo_geocodes_political_2 = compare_residuals_by_axes(df=df_wo_geocodes, 
                                                     residuals='smoothed_resids', 
                                                     axes='ideologyd2', 
                                                     )

df_wo_geocodes_political_2 = compare_residuals_by_axes(df=df_wo_geocodes, 
                                                     residuals='smoothed_resids', 
                                                     axes='ideologyd4', 
                                                     )

df_wo_geocodes_edu_1 = compare_residuals_by_axes(df=df_wo_geocodes, 
                                                     residuals='smoothed_resids', 
                                                     axes='edu1', 
                                                     )




# ['Gender','ideologyd1', 'ideologyd2', 'ideologyd4', 'ideologyd5', 'edu1', 'edu3', 'raced2', 
            #                          'raced3', 'raced4', 'attendd1', 'attendd2', 'attendd3', 'attendd5', 'attendd6',
           ##                           'aged1', 'aged2', 'aged3', 'aged5', 'aged6',
             #                         'PDd1', 'PDd2', 'PDd3', 'PDd5', 'PDd6', 'PDd7']

exclude_cols = ['smoothed_resids', 'mlp_resids', 'lr_resids', 'y_pred_lr', 'y_pred_mlp', 'y_actual']

df_k_greatest_resids = lookup_features_from_top_k_residuals(df_wo_geocodes, 
                                     [col for col in df_wo_geocodes.columns if col not in exclude_cols],
                                     'smoothed_resids', 
                                      k=500)

df_k_greatest_resids.to_csv('res/smoothed_residual_distributions.csv')

df_k_greatest_resids['smoothed_resids'].loc[0]
df_wo_geocodes['PDd1'].value_counts()

df_wo_geocodes.columns






"""Restore and/or retrieve training"""
## Restore a past training session.
exp_path = "/Users/stanleyhuang/Desktop/01 Projects/YAB/cds_climate_change_perception/Climate Change Perceptions/checkpoints/env_pred_tpe_algo_run"
results= tune.Tuner.restore(exp_path, trainable=new_train_fn).get_results()

## Get the best result by looking at the metrics you reported 
best_result = results.get_best_result(metric="valid_loss", mode="min")
checkpoint: Checkpoint = best_result.checkpoint

# Access directory path (if you saved files manually in training)
checkpoint_path = checkpoint.to_directory()

# Example: load training history or model state from that path 
best_configs = results.get_best_result(metric='valid_loss', mode='min').config
merged_configs = {**train_configs, **best_configs}
model_data = torch.load(os.path.join(checkpoint_path, "model.pth"))
model = initialize_model(merged_configs)  
model.load_state_dict(model_data)


"""Plot validation loss as a function of training size."""
data = pd.read_csv(data_file_path_geocoded)
shuffled_data = data.sample(frac=1).reset_index(drop=True) 
cols_to_keep = [col for col in shuffled_data.columns if not col.startswith('cd')]
shuffled_data= shuffled_data[cols_to_keep]
X_c = shuffled_data.drop(['CC12'], axis=1).values.astype(np.float32)
y_c = shuffled_data['CC12'].values.reshape(-1, 1).astype(np.float32)
    
plot_linear_training_validation_loss(X_c, y_c, intervals=10)
best_model= initialize_model(merged_configs)
plot_nn_training_validation_loss(X_c, y_c, intervals=10, configs=merged_configs)


"""Plot residuals of neural network model and baseline psychological model"""

## Reload the best model
best_r2_model = results.get_best_result('best_r2_score', mode='max')
best_configs = best_r2_model.config
merged_configs = {**best_configs, **train_configs}
cp_path = best_r2_model.checkpoint.path
model_data = torch.load(os.path.join(cp_path, 'model.pth'))
model = initialize_model(merged_configs)
model.load_state_dict(model_data)

model.state_dict()

df = pd.read_csv(train_configs['file_path'])
sc = StandardScaler()
X = df.drop(['CC12'], axis=1).values
y = df['CC12'].values - 1
X = sc.fit_transform(X)

lr = LinearRegression()
lr.fit(X, y)

y_pred_lr = lr.predict(X)
lr.score(X, y)

model.eval()
with torch.no_grad():
    X_t = torch.from_numpy(X).float()
    y_t = torch.from_numpy(y).float()
    y_pred_mlp = model(X_t)
    r2_scorer = R2Score()
    r2_scorer.update(y_pred_mlp, y_t.reshape(-1, 1))
    r2_score_eval = r2_scorer.compute()

r2_score_eval
    

"""Constructing a dataset with actual y value, baseline y, and MLP-computed y"""
  
y = y.reshape(-1, 1)
y_pred_lr = y_pred_lr.reshape(-1, 1)
y_pred_mlp_np = y_pred_mlp.cpu().numpy() 

preds_data = np.hstack((y, y_pred_lr, y_pred_mlp_np))

compare_resids = pd.DataFrame(data=preds_data, columns=['y_actual', 'y_pred_lr', 'y_pred_mlp'])

## compute true residuals 
compare_resids['lr_resids'] = compute_true_residuals(compare_resids['y_actual'], compare_resids['y_pred_lr'])
compare_resids['mlp_resids'] = compute_true_residuals(compare_resids['y_actual'], compare_resids['y_pred_mlp'])

## compute smoothed residuals 

compare_resids['smoothed_resids'] = compute_smoothed_residuals(y=compare_resids['y_actual'],
                                                                baseline_y=compare_resids['y_pred_lr'],
                                                                alg_y=compare_resids['y_pred_mlp'])


y_actual = compare_resids['y_actual'] 
lin_mlp_diff = compare_resids['y_pred_lr'] - compare_resids['y_pred_mlp']
plt.hist(lin_mlp_diff)
plt.title('Absolute Linear-MLP difference')
plt.show()

sorted(y_actual.unique())
figs, ax = plt.subplots(nrows=5, figsize=(8, 10))
ax = ax.flatten()

for i, cat in enumerate(sorted(compare_resids['y_actual'].unique())):
    # Filter rows where y_actual == cat
    subset = compare_resids[compare_resids['y_actual'] == cat]

    # Extract predictions
    cat_lin_pred = subset['y_pred_lr']
    cat_mlp_pred = subset['y_pred_mlp']

    # Compute differences
    lin_mlp_diff_for_cat = cat_lin_pred - cat_mlp_pred

    # Plot
    ax[i].hist(lin_mlp_diff_for_cat, color='skyblue', edgecolor='black')
    ax[i].set_title(f"Category {cat}")
    ax[i].axvline(0, color='red', linestyle='--')

plt.tight_layout()
plt.show()




sorted(compare_resids['smoothed_resids'])[-3:-3]

df_geo = pd.read_csv(data_file_path_geocoded)

combined_df = pd.concat([df_geo, compare_resids], axis=1)



compare_residuals_by_axes(combined_df, residuals='smoothed_resids', axes='Gender', 
                          mapping={0.0: 'm', 1.0: 'f'})

compare_residuals_by_axes(combined_df, residuals='smoothed_resids', axes='')

combined_df[combined_df['Gender'] == 0.0]['smoothed_resids'].describe()['count']